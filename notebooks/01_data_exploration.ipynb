{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2a5bd60",
   "metadata": {},
   "source": [
    "# 01 — Data Exploration & Ingestion Sanity Checks\n",
    "\n",
    "This notebook walks through the CertiRAG ingestion pipeline and explores the\n",
    "resulting chunk / span structures. Use it to:\n",
    "\n",
    "1. Load documents and inspect chunking behaviour.\n",
    "2. Visualise span boundaries inside each chunk.\n",
    "3. Verify BM25 + dense index construction.\n",
    "4. Spot-check retrieval quality on sample queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d49e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath(\"..\"))\n",
    "\n",
    "from certirag.config import CertiRAGConfig, ExecutionMode\n",
    "from certirag.ingest.chunker import DocumentChunker\n",
    "from certirag.ingest.indexer import BM25Index, DenseIndex, ChunkStore\n",
    "from certirag.schemas.evidence import EvidenceChunk, EvidenceSpan\n",
    "from certirag.utils import set_all_seeds\n",
    "\n",
    "import textwrap, json\n",
    "from pprint import pprint\n",
    "\n",
    "set_all_seeds(42)\n",
    "cfg = CertiRAGConfig(execution_mode=ExecutionMode.LITE)\n",
    "print(f\"Mode: {cfg.execution_mode}  |  Chunk size: {cfg.chunk_size}  |  Overlap: {cfg.chunk_overlap}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2b36a2",
   "metadata": {},
   "source": [
    "## 1. Chunking a sample document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af996f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_DOC = \"\"\"\n",
    "The Eiffel Tower is a wrought-iron lattice tower on the Champ de Mars in Paris.\n",
    "It is named after the engineer Gustave Eiffel, whose company designed and built the tower.\n",
    "Locally nicknamed \\\"La dame de fer\\\", it was constructed from 1887 to 1889 as the centrepiece\n",
    "of the 1889 World's Fair. Although initially criticised by some of France's leading artists\n",
    "and intellectuals, it has become a global cultural icon of France and one of the most\n",
    "recognisable structures in the world. The tower is 330 metres tall, about the same height\n",
    "as an 81-storey building, and the tallest structure in Paris. Its base is square,\n",
    "measuring 125 metres on each side.\n",
    "\"\"\".strip()\n",
    "\n",
    "chunker = DocumentChunker(config=cfg)\n",
    "chunks = chunker.chunk_document(SAMPLE_DOC, doc_id=\"eiffel_tower\", source=\"wikipedia\")\n",
    "\n",
    "print(f\"Generated {len(chunks)} chunk(s)\\n\")\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"--- Chunk {i} ({chunk.chunk_id}) ---\")\n",
    "    print(f\"  Text length : {len(chunk.text)} chars\")\n",
    "    print(f\"  Spans       : {len(chunk.spans)}\")\n",
    "    for span in chunk.spans:\n",
    "        print(f\"    [{span.span_id}] ({span.start}:{span.end}) → {span.sentence[:60]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42691479",
   "metadata": {},
   "source": [
    "## 2. Span boundary visualisation\n",
    "\n",
    "We highlight each sentence span inside the chunk text using colour codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b074f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLORS = [\"\\033[92m\", \"\\033[94m\", \"\\033[93m\", \"\\033[95m\", \"\\033[96m\"]\n",
    "RESET = \"\\033[0m\"\n",
    "\n",
    "def visualise_spans(chunk: EvidenceChunk) -> None:\n",
    "    \"\"\"Print chunk text with coloured span boundaries.\"\"\"\n",
    "    parts = []\n",
    "    prev_end = 0\n",
    "    for idx, span in enumerate(sorted(chunk.spans, key=lambda s: s.start)):\n",
    "        if span.start > prev_end:\n",
    "            parts.append(chunk.text[prev_end:span.start])\n",
    "        colour = COLORS[idx % len(COLORS)]\n",
    "        parts.append(f\"{colour}[{span.span_id}|{chunk.text[span.start:span.end]}]{RESET}\")\n",
    "        prev_end = span.end\n",
    "    if prev_end < len(chunk.text):\n",
    "        parts.append(chunk.text[prev_end:])\n",
    "    print(\"\".join(parts))\n",
    "\n",
    "for chunk in chunks:\n",
    "    print(f\"\\n=== {chunk.chunk_id} ===\")\n",
    "    visualise_spans(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125f20cf",
   "metadata": {},
   "source": [
    "## 3. Index construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8332b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build BM25 index from the chunks\n",
    "store = ChunkStore()\n",
    "for chunk in chunks:\n",
    "    store.add(chunk)\n",
    "\n",
    "bm25 = BM25Index()\n",
    "bm25.build(chunks)\n",
    "\n",
    "print(f\"ChunkStore size : {len(store)}\")\n",
    "print(f\"BM25 corpus size: {bm25.corpus_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff54603",
   "metadata": {},
   "source": [
    "## 4. BM25 retrieval spot-check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e611870",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    \"How tall is the Eiffel Tower?\",\n",
    "    \"Who designed the Eiffel Tower?\",\n",
    "    \"When was the tower built?\",\n",
    "]\n",
    "\n",
    "for q in queries:\n",
    "    results = bm25.search(q, top_k=3)\n",
    "    print(f\"\\nQuery: {q}\")\n",
    "    for chunk_id, score in results:\n",
    "        chunk = store.get(chunk_id)\n",
    "        preview = chunk.text[:80] if chunk else \"<missing>\"\n",
    "        print(f\"  [{score:.3f}] {chunk_id}: {preview}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596e5a3c",
   "metadata": {},
   "source": [
    "## 5. Schema serialisation round-trip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8957fe69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that chunks survive JSON serialisation\n",
    "for chunk in chunks:\n",
    "    serialised = chunk.model_dump_json()\n",
    "    restored = EvidenceChunk.model_validate_json(serialised)\n",
    "    assert restored.chunk_id == chunk.chunk_id\n",
    "    assert len(restored.spans) == len(chunk.spans)\n",
    "    assert restored.text == chunk.text\n",
    "\n",
    "print(\"✅ All chunks survived serialisation round-trip\")\n",
    "print(f\"\\nSample JSON (first chunk):\\n{json.dumps(json.loads(chunks[0].model_dump_json()), indent=2)[:500]}...\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
